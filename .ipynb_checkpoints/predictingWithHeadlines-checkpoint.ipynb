{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:49926</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>2</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>16.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:49926' processes=2 threads=4, memory=16.00 GB>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import get\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from progressbar import ProgressBar\n",
    "#pbar = ProgressBar()\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras import Sequential\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, progress\n",
    "import os\n",
    "client = Client(n_workers=2, threads_per_worker=2, memory_limit='8GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Tickers\n",
    "\n",
    "So, for some reason, I can't find a nice downloadable csv file that already has all of the tickers in the nyse. I did, however, find a website that can be used to scrape off of!\n",
    "So first, lets get all the tickers we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"curl --ftp-ssl anonymous:jupi@jupi.com \"\n",
    "          \"ftp://ftp.nasdaqtrader.com/SymbolDirectory/nasdaqlisted.txt \"\n",
    "          \"> nasdaq.lst\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading from that file\n",
    "with open('nasdaq.lst', 'r') as f:\n",
    "    file = f.read()\n",
    "find_string = file.split('</html>')\n",
    "ticker_string = find_string[len(find_string)-1]\n",
    "rows = ticker_string.split('\\n')\n",
    "tickers = [row.split('|')[0] for row in rows][2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "for t in tickers:\n",
    "   # try:\n",
    "    print(f'----{t}----')\n",
    "    price_data = get.daily(t)\n",
    "    print(price_data)\n",
    "    news_data = get.News(t)\n",
    "    data.update({t:[price_data, news_data]})\n",
    "    print('------------')\n",
    "   # except AttributeError:\n",
    "    #    pass\n",
    "#In case this expirement needs to be replicated\n",
    "# import pickle\n",
    "# with open('stockReg.pkl', 'wb') as f:\n",
    "#     pickle.dump(data, f)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I haven't finished working on data processing/scraping for this one. However, I was able to figure out the sentiment anaysis I wanted to use.\n",
    "Because WSJ is making scraping hard for me, I just decided to copy a page of headlines related to nvidia into a list, and then test my sentiment analysis method on that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = [\n",
    "    [\"Nvidia's bid for Arm signals loftier chip ambition\"],\n",
    "    ['What are Nvidai and arm? and why are they talking about getting together'],\n",
    "    ['SoftBank Reportedly Nears Deal to Sell Chip Unit to Nvidia'],\n",
    "    ['SoftBank Nears $40 Billion Deal to Sell Arm Holdings'],\n",
    "    ['Here are the biggest stock-market losers on Thursday as the tech sector tanks'],\n",
    "    ['Nvidia Has to Play This Game Perfectly'],\n",
    "    ['These 74 stocks in the S&P 500 hit all-time records on Wednesday'],\n",
    "    ['Nvidia gaming card upgrade is quite a deal, analysts say, as stock breaks more records']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
